{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1eb17d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8cf24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'C:\\\\Users\\\\USER\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()\n",
    "print(breast_cancer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3086b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.DataFrame(breast_cancer_dataset.data,columns= breast_cancer_dataset.feature_names)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c2908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['label']=breast_cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4635d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4ea84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71cb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866b83a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          False         False           False      False            False   \n",
       "1          False         False           False      False            False   \n",
       "2          False         False           False      False            False   \n",
       "3          False         False           False      False            False   \n",
       "4          False         False           False      False            False   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        False         False           False      False            False   \n",
       "565        False         False           False      False            False   \n",
       "566        False         False           False      False            False   \n",
       "567        False         False           False      False            False   \n",
       "568        False         False           False      False            False   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0               False           False                False          False   \n",
       "1               False           False                False          False   \n",
       "2               False           False                False          False   \n",
       "3               False           False                False          False   \n",
       "4               False           False                False          False   \n",
       "..                ...             ...                  ...            ...   \n",
       "564             False           False                False          False   \n",
       "565             False           False                False          False   \n",
       "566             False           False                False          False   \n",
       "567             False           False                False          False   \n",
       "568             False           False                False          False   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                     False  ...          False            False       False   \n",
       "1                     False  ...          False            False       False   \n",
       "2                     False  ...          False            False       False   \n",
       "3                     False  ...          False            False       False   \n",
       "4                     False  ...          False            False       False   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                   False  ...          False            False       False   \n",
       "565                   False  ...          False            False       False   \n",
       "566                   False  ...          False            False       False   \n",
       "567                   False  ...          False            False       False   \n",
       "568                   False  ...          False            False       False   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0               False              False            False   \n",
       "1               False              False            False   \n",
       "2               False              False            False   \n",
       "3               False              False            False   \n",
       "4               False              False            False   \n",
       "..                ...                ...              ...   \n",
       "564             False              False            False   \n",
       "565             False              False            False   \n",
       "566             False              False            False   \n",
       "567             False              False            False   \n",
       "568             False              False            False   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                   False           False                    False  False  \n",
       "1                   False           False                    False  False  \n",
       "2                   False           False                    False  False  \n",
       "3                   False           False                    False  False  \n",
       "4                   False           False                    False  False  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                 False           False                    False  False  \n",
       "565                 False           False                    False  False  \n",
       "566                 False           False                    False  False  \n",
       "567                 False           False                    False  False  \n",
       "568                 False           False                    False  False  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9db5456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       label  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1417e249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c5b6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.462830</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>978.376415</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.192909</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>...</td>\n",
       "      <td>21.134811</td>\n",
       "      <td>29.318208</td>\n",
       "      <td>141.370330</td>\n",
       "      <td>1422.286321</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.146524</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>78.075406</td>\n",
       "      <td>462.790196</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>0.062867</td>\n",
       "      <td>...</td>\n",
       "      <td>13.379801</td>\n",
       "      <td>23.515070</td>\n",
       "      <td>87.005938</td>\n",
       "      <td>558.899440</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.166238</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "label                                                                           \n",
       "0        17.462830     21.604906      115.365377  978.376415         0.102898   \n",
       "1        12.146524     17.914762       78.075406  462.790196         0.092478   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "label                                                                         \n",
       "0              0.145188        0.160775             0.087990       0.192909   \n",
       "1              0.080085        0.046058             0.025717       0.174186   \n",
       "\n",
       "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "label                          ...                                \n",
       "0                    0.062680  ...     21.134811      29.318208   \n",
       "1                    0.062867  ...     13.379801      23.515070   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "label                                                                      \n",
       "0           141.370330  1422.286321          0.144845           0.374824   \n",
       "1            87.005938   558.899440          0.124959           0.182673   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "label                                                          \n",
       "0             0.450606              0.182237        0.323468   \n",
       "1             0.166238              0.074444        0.270246   \n",
       "\n",
       "       worst fractal dimension  \n",
       "label                           \n",
       "0                     0.091530  \n",
       "1                     0.079442  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e538cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_frame.drop(columns='label',axis=1)\n",
    "Y=data_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810db482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Name: label, Length: 569, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d878b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e1e9caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455,) (114,) (455,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape,Y_test.shape,Y_train.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed17667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4c36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "                          keras.layers.Flatten(input_shape=(30,)),\n",
    "                         keras.layers.Dense(20, activation='relu'),\n",
    "                      keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20dc7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b78eb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 2s 50ms/step - loss: 199.4823 - accuracy: 0.3692 - val_loss: 173.5210 - val_accuracy: 0.3478\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 141.3404 - accuracy: 0.3692 - val_loss: 114.9211 - val_accuracy: 0.3478\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 87.0752 - accuracy: 0.3692 - val_loss: 59.0397 - val_accuracy: 0.3478\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 34.1465 - accuracy: 0.3863 - val_loss: 5.5546 - val_accuracy: 0.4565\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9597 - accuracy: 0.7555 - val_loss: 4.3998 - val_accuracy: 0.7391\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.0456 - accuracy: 0.8484 - val_loss: 0.4618 - val_accuracy: 0.8913\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.9917 - accuracy: 0.7848 - val_loss: 0.4059 - val_accuracy: 0.8913\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.5686 - accuracy: 0.8778 - val_loss: 0.2915 - val_accuracy: 0.9565\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.4883 - accuracy: 0.8729 - val_loss: 0.3508 - val_accuracy: 0.8913\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.4333 - accuracy: 0.8533 - val_loss: 0.2777 - val_accuracy: 0.9348\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.3943 - accuracy: 0.8704 - val_loss: 0.2660 - val_accuracy: 0.9348\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.3988 - accuracy: 0.8509 - val_loss: 0.2499 - val_accuracy: 0.9348\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.3173 - accuracy: 0.8729 - val_loss: 0.2476 - val_accuracy: 0.9348\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.3204 - accuracy: 0.8753 - val_loss: 0.2661 - val_accuracy: 0.9348\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.2490 - accuracy: 0.8509 - val_loss: 0.2280 - val_accuracy: 0.9348\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.2416 - accuracy: 0.8900 - val_loss: 0.2204 - val_accuracy: 0.9348\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.1531 - accuracy: 0.8655 - val_loss: 0.2201 - val_accuracy: 0.9348\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.1366 - accuracy: 0.8729 - val_loss: 0.1892 - val_accuracy: 0.9348\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0990 - accuracy: 0.8802 - val_loss: 0.1800 - val_accuracy: 0.9348\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0617 - accuracy: 0.8778 - val_loss: 0.1788 - val_accuracy: 0.9348\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0530 - accuracy: 0.8826 - val_loss: 0.1644 - val_accuracy: 0.9348\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0068 - accuracy: 0.8851 - val_loss: 0.1699 - val_accuracy: 0.9348\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0511 - accuracy: 0.8704 - val_loss: 0.1462 - val_accuracy: 0.9565\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9567 - accuracy: 0.8704 - val_loss: 0.1332 - val_accuracy: 0.9565\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.9031 - accuracy: 0.8875 - val_loss: 0.1342 - val_accuracy: 0.9565\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.9060 - accuracy: 0.8900 - val_loss: 0.1416 - val_accuracy: 0.9348\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.9005 - accuracy: 0.8655 - val_loss: 0.1305 - val_accuracy: 0.9783\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8728 - accuracy: 0.8753 - val_loss: 0.0997 - val_accuracy: 0.9565\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8134 - accuracy: 0.8875 - val_loss: 0.0935 - val_accuracy: 0.9565\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7898 - accuracy: 0.8851 - val_loss: 0.0858 - val_accuracy: 0.9565\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.7712 - accuracy: 0.8778 - val_loss: 0.1025 - val_accuracy: 0.9783\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7737 - accuracy: 0.8973 - val_loss: 0.1210 - val_accuracy: 0.9130\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.7948 - accuracy: 0.8655 - val_loss: 0.1177 - val_accuracy: 0.9783\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.7491 - accuracy: 0.8851 - val_loss: 0.0610 - val_accuracy: 0.9783\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6732 - accuracy: 0.8998 - val_loss: 0.0712 - val_accuracy: 0.9783\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6994 - accuracy: 0.8851 - val_loss: 0.0818 - val_accuracy: 0.9783\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6551 - accuracy: 0.8875 - val_loss: 0.0465 - val_accuracy: 0.9565\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6178 - accuracy: 0.9046 - val_loss: 0.0449 - val_accuracy: 0.9783\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.8851 - val_loss: 0.0601 - val_accuracy: 0.9783\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6461 - accuracy: 0.8851 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6055 - accuracy: 0.9022 - val_loss: 0.0796 - val_accuracy: 0.9783\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6171 - accuracy: 0.9071 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5926 - accuracy: 0.8998 - val_loss: 0.0473 - val_accuracy: 0.9783\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5788 - accuracy: 0.9169 - val_loss: 0.0564 - val_accuracy: 0.9783\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6153 - accuracy: 0.8924 - val_loss: 0.0366 - val_accuracy: 0.9783\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5994 - accuracy: 0.9071 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5864 - accuracy: 0.9022 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5459 - accuracy: 0.9046 - val_loss: 0.0349 - val_accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5535 - accuracy: 0.8998 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5609 - accuracy: 0.9022 - val_loss: 0.0555 - val_accuracy: 0.9783\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6063 - accuracy: 0.9022 - val_loss: 0.0689 - val_accuracy: 0.9783\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5192 - accuracy: 0.9071 - val_loss: 0.0357 - val_accuracy: 0.9783\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.9169 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4933 - accuracy: 0.9022 - val_loss: 0.0394 - val_accuracy: 0.9783\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5400 - accuracy: 0.8949 - val_loss: 0.0764 - val_accuracy: 0.9348\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5525 - accuracy: 0.9071 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5034 - accuracy: 0.9022 - val_loss: 0.0670 - val_accuracy: 0.9783\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5102 - accuracy: 0.9022 - val_loss: 0.0688 - val_accuracy: 0.9783\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.9022 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.9120 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4636 - accuracy: 0.9242 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4236 - accuracy: 0.8998 - val_loss: 0.0322 - val_accuracy: 0.9783\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.9218 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.9169 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4051 - accuracy: 0.9120 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.8998 - val_loss: 0.3186 - val_accuracy: 0.9130\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4684 - accuracy: 0.9071 - val_loss: 0.1174 - val_accuracy: 0.9130\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3900 - accuracy: 0.9095 - val_loss: 0.0483 - val_accuracy: 0.9783\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.3456 - accuracy: 0.9218 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.3617 - accuracy: 0.9193 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3516 - accuracy: 0.9242 - val_loss: 0.0547 - val_accuracy: 0.9783\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.9315 - val_loss: 0.0299 - val_accuracy: 0.9783\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3419 - accuracy: 0.9071 - val_loss: 0.0625 - val_accuracy: 0.9783\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3189 - accuracy: 0.9218 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3571 - accuracy: 0.9095 - val_loss: 0.1225 - val_accuracy: 0.9565\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3301 - accuracy: 0.9120 - val_loss: 0.0538 - val_accuracy: 0.9783\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3159 - accuracy: 0.9242 - val_loss: 0.0356 - val_accuracy: 0.9783\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.9315 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3042 - accuracy: 0.9144 - val_loss: 0.0329 - val_accuracy: 0.9783\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2928 - accuracy: 0.9218 - val_loss: 0.0535 - val_accuracy: 0.9783\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2492 - accuracy: 0.9193 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.2874 - accuracy: 0.9095 - val_loss: 0.1186 - val_accuracy: 0.9348\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3837 - accuracy: 0.8998 - val_loss: 0.1053 - val_accuracy: 0.9348\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3316 - accuracy: 0.9144 - val_loss: 0.1738 - val_accuracy: 0.9130\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3462 - accuracy: 0.8998 - val_loss: 0.2138 - val_accuracy: 0.9130\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.9022 - val_loss: 0.2332 - val_accuracy: 0.9130\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3215 - accuracy: 0.9193 - val_loss: 0.0753 - val_accuracy: 0.9565\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2497 - accuracy: 0.9193 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2283 - accuracy: 0.9291 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 0.9267 - val_loss: 0.0390 - val_accuracy: 0.9783\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.2130 - accuracy: 0.9364 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2166 - accuracy: 0.9291 - val_loss: 0.0503 - val_accuracy: 0.9783\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2136 - accuracy: 0.9291 - val_loss: 0.0821 - val_accuracy: 0.9348\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1972 - accuracy: 0.9291 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1991 - accuracy: 0.9291 - val_loss: 0.0492 - val_accuracy: 0.9783\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.9291 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1852 - accuracy: 0.9389 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9340 - val_loss: 0.1009 - val_accuracy: 0.9348\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1885 - accuracy: 0.9389 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1622 - accuracy: 0.9364 - val_loss: 0.1116 - val_accuracy: 0.9348\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9218 - val_loss: 0.0715 - val_accuracy: 0.9565\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1664 - accuracy: 0.9364 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1557 - accuracy: 0.9462 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1550 - accuracy: 0.9389 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.9364 - val_loss: 0.0698 - val_accuracy: 0.9783\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9340 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1445 - accuracy: 0.9389 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1757 - accuracy: 0.9242 - val_loss: 0.0838 - val_accuracy: 0.9565\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1689 - accuracy: 0.9267 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 0.9413 - val_loss: 0.0893 - val_accuracy: 0.9348\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.9340 - val_loss: 0.1986 - val_accuracy: 0.9130\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.1311 - val_accuracy: 0.9130\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1931 - accuracy: 0.9218 - val_loss: 0.0919 - val_accuracy: 0.9565\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9144 - val_loss: 0.1484 - val_accuracy: 0.9348\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.9340 - val_loss: 0.0784 - val_accuracy: 0.9783\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.9291 - val_loss: 0.1520 - val_accuracy: 0.9130\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1857 - accuracy: 0.9169 - val_loss: 0.1410 - val_accuracy: 0.9348\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1777 - accuracy: 0.9242 - val_loss: 0.2420 - val_accuracy: 0.9130\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2511 - accuracy: 0.9218 - val_loss: 0.1666 - val_accuracy: 0.9130\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9291 - val_loss: 0.1554 - val_accuracy: 0.9130\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9340 - val_loss: 0.0731 - val_accuracy: 0.9783\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.9511 - val_loss: 0.0870 - val_accuracy: 0.9783\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9389 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1776 - accuracy: 0.9267 - val_loss: 0.1637 - val_accuracy: 0.9348\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.9291 - val_loss: 0.0757 - val_accuracy: 0.9783\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1866 - accuracy: 0.9267 - val_loss: 0.1247 - val_accuracy: 0.9348\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9438 - val_loss: 0.0820 - val_accuracy: 0.9783\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9291 - val_loss: 0.0935 - val_accuracy: 0.9783\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1347 - accuracy: 0.9438 - val_loss: 0.0776 - val_accuracy: 0.9783\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9511 - val_loss: 0.0799 - val_accuracy: 0.9565\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1312 - accuracy: 0.9438 - val_loss: 0.0860 - val_accuracy: 0.9783\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1363 - accuracy: 0.9487 - val_loss: 0.1503 - val_accuracy: 0.9348\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1579 - accuracy: 0.9364 - val_loss: 0.0789 - val_accuracy: 0.9565\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1640 - accuracy: 0.9291 - val_loss: 0.2613 - val_accuracy: 0.9130\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2394 - accuracy: 0.8924 - val_loss: 0.0756 - val_accuracy: 0.9565\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 0.9438 - val_loss: 0.1055 - val_accuracy: 0.9565\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1121 - accuracy: 0.9560 - val_loss: 0.1583 - val_accuracy: 0.9130\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 0.9267 - val_loss: 0.0741 - val_accuracy: 0.9783\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.9413 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9389 - val_loss: 0.0825 - val_accuracy: 0.9783\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9364 - val_loss: 0.1472 - val_accuracy: 0.9130\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1385 - accuracy: 0.9413 - val_loss: 0.0837 - val_accuracy: 0.9783\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1239 - accuracy: 0.9364 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1274 - accuracy: 0.9438 - val_loss: 0.0757 - val_accuracy: 0.9783\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1444 - accuracy: 0.9413 - val_loss: 0.0820 - val_accuracy: 0.9565\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 0.9291 - val_loss: 0.1575 - val_accuracy: 0.9348\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9389 - val_loss: 0.1198 - val_accuracy: 0.9348\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1515 - accuracy: 0.9364 - val_loss: 0.0828 - val_accuracy: 0.9783\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1263 - accuracy: 0.9438 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1915 - accuracy: 0.9218 - val_loss: 0.0775 - val_accuracy: 0.9565\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1534 - accuracy: 0.9462 - val_loss: 0.1284 - val_accuracy: 0.9130\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1602 - accuracy: 0.9364 - val_loss: 0.1166 - val_accuracy: 0.9348\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1817 - accuracy: 0.9315 - val_loss: 0.0957 - val_accuracy: 0.9783\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 0.9462 - val_loss: 0.1012 - val_accuracy: 0.9565\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9487 - val_loss: 0.0867 - val_accuracy: 0.9783\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1993 - accuracy: 0.9071 - val_loss: 0.0739 - val_accuracy: 0.9783\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1202 - accuracy: 0.9413 - val_loss: 0.1033 - val_accuracy: 0.9348\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1247 - accuracy: 0.9462 - val_loss: 0.0715 - val_accuracy: 0.9783\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1266 - accuracy: 0.9389 - val_loss: 0.1327 - val_accuracy: 0.9348\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.9438 - val_loss: 0.1057 - val_accuracy: 0.9565\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1298 - accuracy: 0.9462 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1210 - accuracy: 0.9389 - val_loss: 0.2512 - val_accuracy: 0.9130\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1713 - accuracy: 0.9315 - val_loss: 0.0750 - val_accuracy: 0.9565\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9364 - val_loss: 0.1140 - val_accuracy: 0.9348\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1511 - accuracy: 0.9389 - val_loss: 0.1768 - val_accuracy: 0.9130\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.9389 - val_loss: 0.0742 - val_accuracy: 0.9565\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1226 - accuracy: 0.9389 - val_loss: 0.0754 - val_accuracy: 0.9565\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1240 - accuracy: 0.9487 - val_loss: 0.0749 - val_accuracy: 0.9783\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1250 - accuracy: 0.9511 - val_loss: 0.1766 - val_accuracy: 0.9130\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1565 - accuracy: 0.9291 - val_loss: 0.0898 - val_accuracy: 0.9565\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9487 - val_loss: 0.1173 - val_accuracy: 0.9348\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2001 - accuracy: 0.9267 - val_loss: 0.1615 - val_accuracy: 0.9348\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1652 - accuracy: 0.9242 - val_loss: 0.1012 - val_accuracy: 0.9348\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.9340 - val_loss: 0.1170 - val_accuracy: 0.9130\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9438 - val_loss: 0.0863 - val_accuracy: 0.9565\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1639 - accuracy: 0.9389 - val_loss: 0.1313 - val_accuracy: 0.9348\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 0.9438 - val_loss: 0.0819 - val_accuracy: 0.9783\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1185 - accuracy: 0.9389 - val_loss: 0.1109 - val_accuracy: 0.9348\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1411 - accuracy: 0.9462 - val_loss: 0.0736 - val_accuracy: 0.9783\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9315 - val_loss: 0.2154 - val_accuracy: 0.9348\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1360 - accuracy: 0.9389 - val_loss: 0.0946 - val_accuracy: 0.9348\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1909 - accuracy: 0.9315 - val_loss: 0.1028 - val_accuracy: 0.9783\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1324 - accuracy: 0.9389 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9413 - val_loss: 0.3167 - val_accuracy: 0.9130\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2392 - accuracy: 0.9218 - val_loss: 0.0689 - val_accuracy: 0.9783\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1168 - accuracy: 0.9511 - val_loss: 0.0816 - val_accuracy: 0.9783\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 0.9413 - val_loss: 0.0932 - val_accuracy: 0.9348\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1194 - accuracy: 0.9438 - val_loss: 0.0764 - val_accuracy: 0.9565\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1434 - accuracy: 0.9438 - val_loss: 0.0771 - val_accuracy: 0.9783\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9535 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.9413 - val_loss: 0.0914 - val_accuracy: 0.9783\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1192 - accuracy: 0.9535 - val_loss: 0.0942 - val_accuracy: 0.9565\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1189 - accuracy: 0.9511 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1114 - accuracy: 0.9535 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1200 - accuracy: 0.9487 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1222 - accuracy: 0.9487 - val_loss: 0.0759 - val_accuracy: 0.9565\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1100 - accuracy: 0.9462 - val_loss: 0.1042 - val_accuracy: 0.9783\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.9413 - val_loss: 0.1434 - val_accuracy: 0.9130\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.9487 - val_loss: 0.1121 - val_accuracy: 0.9348\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1208 - accuracy: 0.9511 - val_loss: 0.1322 - val_accuracy: 0.9348\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,validation_split=0.1,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11798331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a08352e610>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "\n",
    "plt.legend(['training data','validation data'],loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343e1cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2194 - accuracy: 0.8158\n",
      "0.8157894611358643\n"
     ]
    }
   ],
   "source": [
    "loss , accuracy = model.evaluate(X_test_std,Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083ccec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8470d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04462793 -1.41612656 -0.05903514 -0.16234067  2.0202457  -0.11323672\n",
      "  0.18500609  0.47102419  0.63336386  0.26335737  0.53209124  2.62763999\n",
      "  0.62351167  0.11405261  1.01246781  0.41126289  0.63848593  2.88971815\n",
      " -0.41675911  0.74270853 -0.32983699 -1.67435595 -0.36854552 -0.38767294\n",
      "  0.32655007 -0.74858917 -0.54689089 -0.18278004 -1.23064515 -0.6268286 ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d952c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca919d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 2)\n",
      "[0.8527004 0.4266498]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape)\n",
    "print(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b718da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04462793 -1.41612656 -0.05903514 ... -0.18278004 -1.23064515\n",
      "  -0.6268286 ]\n",
      " [ 0.24583601 -0.06219797  0.21802678 ...  0.54129749  0.11047691\n",
      "   0.0483572 ]\n",
      " [-1.26115925 -0.29051645 -1.26499659 ... -1.35138617  0.269338\n",
      "  -0.28231213]\n",
      " ...\n",
      " [ 0.72709489  0.45836817  0.75277276 ...  1.46701686  1.19909344\n",
      "   0.65319961]\n",
      " [ 0.25437907  1.33054477  0.15659489 ... -1.29043534 -2.22561725\n",
      "  -1.59557344]\n",
      " [ 0.84100232 -0.06676434  0.8929529  ...  2.15137705  0.35629355\n",
      "   0.37459546]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7305311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.52700412e-01 4.26649809e-01]\n",
      " [5.09247303e-01 8.24442029e-01]\n",
      " [5.75656593e-01 9.99029458e-01]\n",
      " [1.00000000e+00 5.20780595e-05]\n",
      " [6.00365400e-01 4.07580167e-01]\n",
      " [9.99924600e-01 1.00951558e-02]\n",
      " [3.99031609e-01 5.81328273e-01]\n",
      " [8.92262876e-01 9.99981046e-01]\n",
      " [6.40274882e-01 9.92496431e-01]\n",
      " [8.64498198e-01 9.99676764e-01]\n",
      " [5.78393698e-01 9.64797974e-01]\n",
      " [4.95231003e-01 8.96268427e-01]\n",
      " [4.24162328e-01 7.45761037e-01]\n",
      " [5.66538930e-01 9.55172598e-01]\n",
      " [6.57933950e-01 9.98779416e-01]\n",
      " [9.86785948e-01 9.18025896e-02]\n",
      " [7.01581120e-01 9.97482657e-01]\n",
      " [6.42590523e-01 5.68081319e-01]\n",
      " [7.24889457e-01 9.98499990e-01]\n",
      " [9.99969423e-01 1.25781251e-02]\n",
      " [1.00000000e+00 1.13277729e-05]\n",
      " [6.82315230e-01 9.95140612e-01]\n",
      " [4.88815367e-01 9.92861807e-01]\n",
      " [8.52956831e-01 9.99826550e-01]\n",
      " [7.32432961e-01 9.78092849e-01]\n",
      " [9.59156990e-01 1.91249207e-01]\n",
      " [6.63246930e-01 9.82680917e-01]\n",
      " [6.99218035e-01 9.06510413e-01]\n",
      " [5.36526918e-01 8.33335757e-01]\n",
      " [6.93005085e-01 3.87173921e-01]\n",
      " [7.98928499e-01 9.93940353e-01]\n",
      " [6.08851612e-01 9.91482794e-01]\n",
      " [7.71912396e-01 9.87077713e-01]\n",
      " [8.27722371e-01 1.52714208e-01]\n",
      " [9.99604106e-01 2.41939835e-02]\n",
      " [8.49617541e-01 3.12969565e-01]\n",
      " [7.76898861e-01 9.99990582e-01]\n",
      " [6.33372962e-01 9.94078875e-01]\n",
      " [5.80886126e-01 9.97355759e-01]\n",
      " [4.83495444e-01 7.40408659e-01]\n",
      " [1.00000000e+00 1.16341034e-04]\n",
      " [5.54045618e-01 5.08642077e-01]\n",
      " [1.51404470e-01 9.98117328e-01]\n",
      " [8.13766360e-01 5.33995271e-01]\n",
      " [9.94648397e-01 1.16286725e-01]\n",
      " [6.45780265e-01 9.92167294e-01]\n",
      " [7.37861395e-01 9.93142486e-01]\n",
      " [3.18454683e-01 9.98760104e-01]\n",
      " [6.14977062e-01 5.33662617e-01]\n",
      " [9.35011148e-01 2.67293751e-01]\n",
      " [8.53431165e-01 9.99270558e-01]\n",
      " [5.74008763e-01 3.78253073e-01]\n",
      " [5.70364237e-01 9.71499503e-01]\n",
      " [7.72913516e-01 9.99508917e-01]\n",
      " [6.22616529e-01 9.98221338e-01]\n",
      " [5.55603623e-01 7.24637628e-01]\n",
      " [4.44509059e-01 9.85363007e-01]\n",
      " [6.69431865e-01 9.99778152e-01]\n",
      " [1.00000000e+00 6.02074258e-04]\n",
      " [5.99158764e-01 5.47100306e-01]\n",
      " [5.90245366e-01 8.11113656e-01]\n",
      " [9.99999881e-01 9.73080110e-04]\n",
      " [7.29637742e-01 9.98135328e-01]\n",
      " [9.99877930e-01 2.46912707e-02]\n",
      " [5.92778206e-01 8.85927677e-01]\n",
      " [9.99999881e-01 7.45124184e-04]\n",
      " [9.93667364e-01 8.41785073e-02]\n",
      " [9.59675729e-01 2.47791573e-01]\n",
      " [8.17541957e-01 9.99528885e-01]\n",
      " [9.97277796e-01 2.19902676e-02]\n",
      " [9.99989033e-01 1.07925311e-02]\n",
      " [9.99980092e-01 1.86729971e-02]\n",
      " [6.00198984e-01 9.95698273e-01]\n",
      " [8.85898650e-01 3.67030442e-01]\n",
      " [8.48080873e-01 9.99910593e-01]\n",
      " [9.43469465e-01 2.17933893e-01]\n",
      " [3.10501307e-01 9.63992119e-01]\n",
      " [7.89276421e-01 9.96493459e-01]\n",
      " [7.80812860e-01 9.92778540e-01]\n",
      " [8.00629556e-01 2.86109060e-01]\n",
      " [9.99849260e-01 3.16573158e-02]\n",
      " [9.88059044e-01 1.63219184e-01]\n",
      " [9.99443531e-01 2.02860646e-02]\n",
      " [7.90479541e-01 3.22411627e-01]\n",
      " [4.77015644e-01 9.70776379e-01]\n",
      " [5.59289515e-01 9.74508584e-01]\n",
      " [9.99987841e-01 1.99208874e-02]\n",
      " [6.66797519e-01 9.93185103e-01]\n",
      " [7.61978030e-01 4.61182058e-01]\n",
      " [1.00000000e+00 1.65022793e-04]\n",
      " [6.49436891e-01 9.70594168e-01]\n",
      " [6.88605607e-01 9.95650291e-01]\n",
      " [9.97674823e-01 1.70405328e-01]\n",
      " [9.99925256e-01 9.01145581e-03]\n",
      " [3.54001820e-01 4.86405343e-01]\n",
      " [6.96092367e-01 9.89692152e-01]\n",
      " [9.99604583e-01 3.08737159e-02]\n",
      " [9.99855220e-01 8.55171029e-03]\n",
      " [5.52418292e-01 9.97909486e-01]\n",
      " [8.57705414e-01 9.99946833e-01]\n",
      " [8.74782085e-01 9.99971271e-01]\n",
      " [9.71411407e-01 3.43457460e-01]\n",
      " [9.98770118e-01 2.34761480e-02]\n",
      " [9.99998152e-01 3.31613072e-03]\n",
      " [5.59745610e-01 9.97967780e-01]\n",
      " [5.64134121e-01 9.10884202e-01]\n",
      " [9.88598168e-01 2.60562956e-01]\n",
      " [9.95024383e-01 1.02622613e-01]\n",
      " [1.15283243e-01 9.94227529e-01]\n",
      " [3.34853470e-01 9.70736742e-01]\n",
      " [9.89876747e-01 9.14060026e-02]\n",
      " [9.93725002e-01 1.24191776e-01]\n",
      " [6.94804251e-01 9.92503166e-01]\n",
      " [9.98279750e-01 7.35164061e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0644df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 0.25, 0.56]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "my_list = [0.25, 0.56]\n",
    "\n",
    "index_of_max_value = np.argmax(my_list)\n",
    "print(my_list)\n",
    "print(index_of_max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1d08c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_labels = [np.argmax(i) for i in Y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "502c7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a0d2177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "[[0.6545965 0.9996838]]\n",
      "[1]\n",
      "The tumor is Benign\n"
     ]
    }
   ],
   "source": [
    "input_data = (11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)\n",
    "\n",
    "\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "\n",
    "input_data_std = scaler.transform(input_data_reshaped)\n",
    "\n",
    "prediction = model.predict(input_data_std)\n",
    "print(prediction)\n",
    "\n",
    "prediction_label = [np.argmax(prediction)]\n",
    "print(prediction_label)\n",
    "\n",
    "if(prediction_label[0] == 0):\n",
    "  print('The tumor is Malignant')\n",
    "\n",
    "else:\n",
    "  print('The tumor is Benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44f96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
